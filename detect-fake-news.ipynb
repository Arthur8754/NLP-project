{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupe 6 : évaluation de caractères fake news de messages sur les réseaux sociaux\n",
    "\n",
    "Le but de ce projet est, à partir d'un ensemble de tweets, d'établir une liste de tweets dont il faut vérifier l'information, triée par ordre de priorité."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/arthur/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/arthur/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.23.3)\n",
      "Requirement already satisfied: nltk in /home/arthur/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: spacy in /home/arthur/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (3.5.1)\n",
      "Requirement already satisfied: gensim in /home/arthur/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/arthur/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/arthur/.local/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 3)) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /home/arthur/.local/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk->-r requirements.txt (line 3)) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /home/arthur/.local/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 3)) (4.65.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (0.10.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (1.10.6)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy->-r requirements.txt (line 4)) (59.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy->-r requirements.txt (line 4)) (2.25.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (1.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (6.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (8.1.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: jinja2 in /home/arthur/.local/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from spacy->-r requirements.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/arthur/.local/lib/python3.10/site-packages (from gensim->-r requirements.txt (line 5)) (1.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/arthur/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->-r requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/arthur/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 4)) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/arthur/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 4)) (0.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->spacy->-r requirements.txt (line 4)) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/arthur/.local/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: jinja2 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.25.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.6)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (59.6.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/arthur/.local/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/arthur/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/arthur/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/arthur/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/arthur/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/arthur/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\") #gestion de la ponctuation pour la tokenization.\n",
    "nltk.download('vader_lexicon') #lexique de nltk pour la positivité des mots."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture de l'ensemble d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1\n",
       "1                Forest fire near La Ronge Sask. Canada       1\n",
       "2     All residents asked to 'shelter in place' are ...       1\n",
       "3     13,000 people receive #wildfires evacuation or...       1\n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1\n",
       "...                                                 ...     ...\n",
       "7608  Two giant cranes holding a bridge collapse int...       1\n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1\n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
       "7611  Police investigating after an e-bike collided ...       1\n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0                    Just happened a terrible car crash\n",
       "1     Heard about #earthquake is different cities, s...\n",
       "2     there is a forest fire at spot pond, geese are...\n",
       "3              Apocalypse lighting. #Spokane #wildfires\n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan\n",
       "...                                                 ...\n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
       "3259  Storm in RI worse than last hurricane. My city...\n",
       "3260  Green Line derailment in Chicago http://t.co/U...\n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "3262  #CityofCalgary has activated its Municipal Eme...\n",
       "\n",
       "[3263 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.read.ReadData import ReadData\n",
    "\n",
    "reader = ReadData(train_path = \"data/train.csv\",test_path = \"data/test.csv\")\n",
    "df_train = reader.read_train()\n",
    "df_test = reader.read_test()\n",
    "display(df_train)\n",
    "display(df_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des caractéristiques :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longueur des tweets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet : 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'\n",
      "Longueur en caractères : 69\n",
      "\n",
      "Représentation en tokens : ['Our', 'Deeds', 'are', 'the', 'Reason', 'of', 'this', '#', 'earthquake', 'May', 'ALLAH', 'Forgive', 'us', 'all']\n",
      "Longueur en tokens : 14\n"
     ]
    }
   ],
   "source": [
    "# Test sur 1 tweet :\n",
    "from src.features.tweetLevel import tweetLevel\n",
    "from src.features.tokenization import tokenization\n",
    "\n",
    "extractor_features = tweetLevel()\n",
    "tokenizer = tokenization()\n",
    "\n",
    "tweet = df_train[\"text\"][0]\n",
    "tokenized_tweet = tokenizer.tokenize_tweet(tweet)\n",
    "len_in_char = extractor_features.get_length_in_characters(tweet)\n",
    "len_in_tokens = extractor_features.get_length_in_tokens(tweet)\n",
    "\n",
    "print(f\"Tweet : '{tweet}'\")\n",
    "print(f\"Longueur en caractères : {len_in_char}\")\n",
    "print(\"\")\n",
    "print(f\"Représentation en tokens : {tokenized_tweet}\")\n",
    "print(f\"Longueur en tokens : {len_in_tokens}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment du tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet : 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'\n",
      "Score de positivité du tweet : 0.149\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = extractor_features.get_positive_sentiment_score(tweet)\n",
    "\n",
    "print(f\"Tweet : '{tweet}'\")\n",
    "print(f\"Score de positivité du tweet : {sentiment_analysis}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tags du tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet : 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'\n",
      "Représentation en tokens : ['Our', 'Deeds', 'are', 'the', 'Reason', 'of', 'this', '#', 'earthquake', 'May', 'ALLAH', 'Forgive', 'us', 'all']\n",
      "pos_tags : [('Our', 'PRP$'), ('Deeds', 'NNS'), ('are', 'VBP'), ('the', 'DT'), ('Reason', 'NNP'), ('of', 'IN'), ('this', 'DT'), ('#', '#'), ('earthquake', 'NN'), ('May', 'NNP'), ('ALLAH', 'NNP'), ('Forgive', 'NNP'), ('us', 'PRP'), ('all', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = extractor_features.get_pos_tags(tweet)\n",
    "print(f\"Tweet : '{tweet}'\")\n",
    "print(f\"Représentation en tokens : {tokenized_tweet}\")\n",
    "print(f\"pos_tags : {pos_tags}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entités du tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet : 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'\n",
      "Entités : [('May ALLAH Forgive', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "entity_types = extractor_features.get_entity_types(tweet)\n",
    "print(f\"Tweet : '{tweet}'\")\n",
    "print(f\"Entités : {entity_types}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 8.1681199e-03, -4.4430327e-03,  8.9854337e-03,  8.2536647e-03,\n",
       "        -4.4352221e-03,  3.0310510e-04,  4.2744912e-03, -3.9263200e-03,\n",
       "        -5.5599655e-03, -6.5123225e-03, -6.7073823e-04, -2.9592158e-04,\n",
       "         4.4630850e-03, -2.4740540e-03, -1.7260908e-04,  2.4618758e-03,\n",
       "         4.8675989e-03, -3.0808449e-05, -6.3394094e-03, -9.2608072e-03,\n",
       "         2.6657581e-05,  6.6618943e-03,  1.4660227e-03, -8.9665223e-03,\n",
       "        -7.9386048e-03,  6.5519023e-03, -3.7856805e-03,  6.2549924e-03,\n",
       "        -6.6810320e-03,  8.4796622e-03, -6.5163244e-03,  3.2880199e-03,\n",
       "        -1.0569858e-03, -6.7875278e-03, -3.2875966e-03, -1.1614120e-03,\n",
       "        -5.4709399e-03, -1.2113475e-03, -7.5633135e-03,  2.6466595e-03,\n",
       "         9.0701487e-03, -2.3772502e-03, -9.7651005e-04,  3.5135616e-03,\n",
       "         8.6650876e-03, -5.9218528e-03, -6.8875779e-03, -2.9329848e-03,\n",
       "         9.1476962e-03,  8.6626766e-04, -8.6784009e-03, -1.4469790e-03,\n",
       "         9.4794659e-03, -7.5494875e-03, -5.3580985e-03,  9.3165627e-03,\n",
       "        -8.9737261e-03,  3.8259076e-03,  6.6544057e-04,  6.6607012e-03,\n",
       "         8.3127534e-03, -2.8507852e-03, -3.9923131e-03,  8.8979173e-03,\n",
       "         2.0896459e-03,  6.2489416e-03, -9.4457148e-03,  9.5901238e-03,\n",
       "        -1.3483083e-03, -6.0521150e-03,  2.9925345e-03, -4.5661093e-04,\n",
       "         4.7064926e-03, -2.2830211e-03, -4.1378425e-03,  2.2778988e-03,\n",
       "         8.3543835e-03, -4.9956059e-03,  2.6686788e-03, -7.9905549e-03,\n",
       "        -6.7733466e-03, -4.6766878e-04, -8.7677278e-03,  2.7894378e-03,\n",
       "         1.5985954e-03, -2.3196924e-03,  5.0037908e-03,  9.7487867e-03,\n",
       "         8.4542679e-03, -1.8802249e-03,  2.0581519e-03, -4.0036892e-03,\n",
       "        -8.2414057e-03,  6.2779556e-03, -1.9491815e-03, -6.6620467e-04,\n",
       "        -1.7713320e-03, -4.5356657e-03,  4.0617096e-03, -4.2701806e-03],\n",
       "       dtype=float32),\n",
       " array([-8.6196875e-03,  3.6657380e-03,  5.1898835e-03,  5.7419385e-03,\n",
       "         7.4669183e-03, -6.1676754e-03,  1.1056137e-03,  6.0472824e-03,\n",
       "        -2.8400505e-03, -6.1735227e-03, -4.1022300e-04, -8.3689485e-03,\n",
       "        -5.6000124e-03,  7.1045388e-03,  3.3525396e-03,  7.2256695e-03,\n",
       "         6.8002474e-03,  7.5307419e-03, -3.7891543e-03, -5.6180597e-04,\n",
       "         2.3483764e-03, -4.5190323e-03,  8.3887316e-03, -9.8581640e-03,\n",
       "         6.7646410e-03,  2.9144168e-03, -4.9328315e-03,  4.3981876e-03,\n",
       "        -1.7395747e-03,  6.7113843e-03,  9.9648498e-03, -4.3624435e-03,\n",
       "        -5.9933780e-04, -5.6956373e-03,  3.8508223e-03,  2.7866268e-03,\n",
       "         6.8910765e-03,  6.1010956e-03,  9.5384968e-03,  9.2734173e-03,\n",
       "         7.8980681e-03, -6.9895042e-03, -9.1558648e-03, -3.5575271e-04,\n",
       "        -3.0998408e-03,  7.8943167e-03,  5.9385742e-03, -1.5456629e-03,\n",
       "         1.5109634e-03,  1.7900408e-03,  7.8175711e-03, -9.5101865e-03,\n",
       "        -2.0553112e-04,  3.4691966e-03, -9.3897223e-04,  8.3817719e-03,\n",
       "         9.0107834e-03,  6.5365066e-03, -7.1162102e-04,  7.7104042e-03,\n",
       "        -8.5343346e-03,  3.2071066e-03, -4.6379971e-03, -5.0889552e-03,\n",
       "         3.5896183e-03,  5.3703394e-03,  7.7695143e-03, -5.7665063e-03,\n",
       "         7.4333609e-03,  6.6254963e-03, -3.7098003e-03, -8.7456414e-03,\n",
       "         5.4374672e-03,  6.5097557e-03, -7.8755023e-04, -6.7098560e-03,\n",
       "        -7.0859254e-03, -2.4970602e-03,  5.1432536e-03, -3.6652375e-03,\n",
       "        -9.3700597e-03,  3.8267397e-03,  4.8844791e-03, -6.4285635e-03,\n",
       "         1.2085581e-03, -2.0748770e-03,  2.4403334e-05, -9.8835090e-03,\n",
       "         2.6920044e-03, -4.7501065e-03,  1.0876465e-03, -1.5762246e-03,\n",
       "         2.1966731e-03, -7.8815762e-03, -2.7171839e-03,  2.6631986e-03,\n",
       "         5.3466819e-03, -2.3915148e-03, -9.5100943e-03,  4.5058788e-03],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.features.word2vec import word2vec\n",
    "\n",
    "train_set = [\"Very beautiful\",\"I would like to eat apple\",\"Yes\"]\n",
    "word2vec_creator = word2vec(train_set)\n",
    "word2vec_creator.predict(\"beautiful apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
